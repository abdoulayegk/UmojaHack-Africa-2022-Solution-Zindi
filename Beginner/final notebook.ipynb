{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d2e74-0bd0-4b3d-a00f-99f8ec6c75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as mn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "random_state= 42\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2088c-97d0-4466-a7e9-8b71c27ddf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "#ss = pd.read_csv('SampleSubmission.csv')\n",
    "ss = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c691b2-c86d-4e42-97ab-3b7b4acd3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55554da-d3c9-4093-9111-52df375407b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba592a-5cc9-451a-9ec8-5b355708f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0f377-beea-4ad2-8df4-eba6317c00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea6cc8-3810-4c4b-955b-e188f0776b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09fd81-134c-4a21-a98e-819cee2adba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn.matrix(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9aaa9b-22ea-4735-82db-147da600fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn.matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2d358-f6cc-4381-81ec-c01f4bb530bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('ID',axis=1)\n",
    "test = test.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c2a9c-469d-49fe-ba73-b4c6fa4931e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'Sensor1_PM2.5':'Offset_fault'].describe().T.style.bar(subset=['mean'], color='#206ff2')\\\n",
    "                            .background_gradient(subset=['std'], cmap='Reds')\\\n",
    "                            .background_gradient(subset=['50%'], cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a029d1-e567-466b-ae4c-16cb1ed1cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's visualize \n",
    "sns.countplot(train.Offset_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836abe05-d395-42df-8a69-862858cc7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day, month year and hour from the Datetime column\n",
    "# day\n",
    "def converte_dates(df):\n",
    "    \n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    \n",
    "    #\n",
    "    df['Datetime_day'] = df.Datetime.dt.day\n",
    "\n",
    "    # month\n",
    "    df['Datetime_month'] = df.Datetime.dt.month\n",
    "\n",
    "    # year\n",
    "    df['Datetime_year'] = df.Datetime.dt.year\n",
    "\n",
    "    # hour\n",
    "    df['Datetime_hour'] = df.Datetime.dt.hour\n",
    "    \n",
    "    # minute\n",
    "    df['Datetime_minute'] = df.Datetime.dt.minute\n",
    "    \n",
    "    # day of week\n",
    "    df['Datetime_dayofweek'] = df.Datetime.dt.weekday\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train = converte_dates(train)\n",
    "test = converte_dates(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab44f97-165f-441c-8ce7-b8407be71c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_features(df):\n",
    "    df['is_morning'] = (6 <= df['Datetime_hour']) & (df['Datetime_hour'] < 12)#.median()\n",
    "    df['is_afternoon'] = (12 <= df['Datetime_hour']) & (df['Datetime_hour'] < 18)#.median()\n",
    "    df['is_evening'] = (18 <= df['Datetime_hour']) & (df['Datetime_hour'] <= 23)#.median()\n",
    "    df['is_night'] = (0 <= df['Datetime_hour']) & (df['Datetime_hour'] < 6)#.median()\n",
    "    return df\n",
    "\n",
    "\n",
    "train = more_features(train)\n",
    "test = more_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c175e4-3140-44db-90fc-ad281e612785",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83581875-7e78-42d9-b519-6ca8be453c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,8)\n",
    "train.boxplot(column=['Sensor1_PM2.5',\n",
    " 'Sensor2_PM2.5',\n",
    " 'Temperature',\n",
    " 'Relative_Humidity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a11cec-6e60-4290-bf67-fa959ccad208",
   "metadata": {},
   "source": [
    "From the  above plot we can see that our features **Sensor1_PM2.5 and Sensor2_MP2.5** is show a huge outliers so for the first time I try dropping them then we might loss so many data I decide to keep it as it and I will scale the features later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1082590-169d-41d9-ac5b-8a8e540281a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3930140-0622-443f-91a1-522428ba3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Datetime',axis=1)\n",
    "test = test.drop('Datetime',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef92c6a-82dc-4102-b545-ba8d7806c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = train.drop(['Offset_fault','Datetime_month','Datetime_year'], axis=1).columns\n",
    "# for i in range(len(feature_names)-1):\n",
    "#     figure = plt.figure()\n",
    "#     ax = sns.boxplot(x='Offset_fault', y=feature_names[i], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac76b1b-d9e3-4d2f-b4c8-f5b40a7b6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed434ec-72b5-4331-87a4-e8adbb23f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Offset_fault',axis=1)\n",
    "y = train['Offset_fault']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a4d16-3460-49fd-8a7a-cc22c162e889",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here I am capturing NaN per row and making new feature.<br>\n",
    "I am doing this because sometime missing carry signal so we only give it to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9871-2f80-4d0e-ae4e-78701772d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['NaN_row'] = df.isna().sum(axis=1)\n",
    "    df['std'] = df.std(axis=1)\n",
    "    return df\n",
    "\n",
    "X = feature_engineering(X)\n",
    "test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b8038-1a72-4b70-8120-25f9ad540a0d",
   "metadata": {},
   "source": [
    "# added code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bd9a3-f997-4a70-a352-0a3ff5320f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    #df['AverageTemperature'] = df['Temperature'].mean(axis=0)\n",
    "    df['AverageTemperature'] = df.groupby('Relative_Humidity')['Temperature'].transform('mean')\n",
    "    df['AverageHumidity'] = df.groupby('Temperature')['Relative_Humidity'].transform('mean')\n",
    "    # df['Relative_Humidity'] = df['Relative_Humidity'].mean(axis=0)\n",
    "    df['Total_sensor'] = df['Sensor1_PM2.5'] + df['Sensor2_PM2.5']\n",
    "    \n",
    "    return df\n",
    "\n",
    "X = feature_engineering(X)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3f2de-6c94-41c9-8932-4ef2d36ecf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e732479-55ed-4cb8-af10-0a830232f971",
   "metadata": {},
   "source": [
    "### Pipeline for data transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970be33-49aa-4dc1-9079-5b1a9df1d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "X = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\n",
    "test = pd.DataFrame(columns=test.columns, data=pipeline.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2dd76-d408-4f38-a8b5-3e7ad04000e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,10))\n",
    "sns.heatmap(train.corr(), cmap='YlGnBu', vmax=1.0, vmin=-1.0, annot = True, annot_kws={\"size\": 15})\n",
    "plt.title('Correlation between numeric features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a8be8-be72-4702-9347-5bf4a1c0ba5f",
   "metadata": {},
   "source": [
    " Our Sensor1 and Sensor2 is showing highly correlation we are supposed to drop one but I did combine them to find the total sensor so for now I am going to keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fb339-1233-49e8-ab8c-09da17def473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state= 42, test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628f742-1052-4b5e-8c97-a7b2556e2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lgb_params = {\n",
    "#     \"objective\" : \"binary\",\n",
    "#     \"metric\" : \"accuracy\",\n",
    "#     \"boosting\": 'gbdt',\n",
    "#     # #\"max_depth\" : -1,\n",
    "#     # \"num_leaves\" : 13,\n",
    "#     # \"learning_rate\" : 0.01,\n",
    "#     # \"bagging_freq\": 5,\n",
    "#     # \"bagging_fraction\" : 0.4,\n",
    "#     # \"feature_fraction\" : 0.05,\n",
    "#     # \"min_data_in_leaf\": 80,\n",
    "#     # \"min_sum_heassian_in_leaf\": 10,\n",
    "#     # \"tree_learner\": \"serial\",\n",
    "#     # \"boost_from_average\": \"false\",\n",
    "#     #\"lambda_l1\" : 5,\n",
    "#     #\"lambda_l2\" : 5,\n",
    "#     \"bagging_seed\" : random_state,\n",
    "#     \"verbosity\" : 1,\n",
    "#     \"seed\": random_state\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "params = {'n_estimators': 1040, 'max_depth': 3, 'reg_lambda': 0.16661201237472856, \n",
    "          'colsample_bytree': 0.9064439932687255, 'num_leaves': 450, \n",
    "          'min_child_samples': 21, 'subsample': 0.5564713817638391, 'random_state':0}\n",
    "lgb= LGBMClassifier(**params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lgb = LGBMClassifier(\n",
    "#     objective='binary',learning_rate=0.1, class_weight='balanced',\n",
    "#     boosting_type ='gbdt',\n",
    "#     bagging_seed = random_state,\n",
    "#     importance_type='gain',\n",
    "#     metric = \"accuracy\",\n",
    "# )\n",
    "                    \n",
    "lgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e49fb-c9dc-4f80-bf4c-b9f004135197",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5058cb-d082-4352-a9ad-2b1c67b7fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555f940-6ef5-4e44-aa1e-77e76dd202f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Accuracy: {lgb.score(X_train, y_train):0.3f}\")\n",
    "print(f\"Test Accuracy: {lgb.score(X_test, y_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e76e8-3989-4207-a5e9-088a343c9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb = lgb.predict(test)\n",
    "sub = pd.DataFrame({'ID':ss,'Offset_fault':pred_lgb})\n",
    "sub.to_csv('lgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd087c-4ee2-4ff2-8117-b3b7830e2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier()\n",
    "lgb.fit(X_train.values, y_train)\n",
    "y_pred = lgb.predict(X_test)\n",
    "print(f'Accuracy score on the X_test is: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a7082-15da-41d8-b294-6011994178be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "impo_df = pd.DataFrame({'feature': X.columns, 'importance': lgb.feature_importances_}).set_index('feature').sort_values(by = 'importance', ascending = False)\n",
    "impo_df = impo_df[:13].sort_values(by = 'importance', ascending = True)\n",
    "impo_df.plot(kind = 'barh', figsize = (10, 10), color = 'purple')\n",
    "plt.legend(loc = 'center right')\n",
    "plt.title('Bar chart showing feature importance', color = 'indigo', fontsize = 14)\n",
    "plt.xlabel('Features', fontsize = 12, color = 'indigo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4450ae-267b-45fe-af94-6841ed503e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006fac0-7579-45cb-a26d-b99b02956bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['NaN_row','Datetime_year']\n",
    "test_df = test.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b171ab-fc80-4338-9e81-23c4fce153af",
   "metadata": {},
   "source": [
    "Now let's try to use stratify so make sure data label is well distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a6d09-afc4-4042-86c5-3acba8743d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X.drop(to_drop,axis=1), y, random_state=42, test_size=0.05,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb3ecb-ad99-4aaf-8683-403967296dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(objective='binary',learning_rate=0.1,class_weight='balanced')\n",
    "lgb.fit(X_train.values, y_train)\n",
    "y_pred = lgb.predict(X_test)\n",
    "print(f'Accuracy score on the X_test is: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cafe90-4bca-45f2-a64a-01e2da7d2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb = lgb.predict(test_df)\n",
    "sub = pd.DataFrame({'ID':ss,'Offset_fault':pred_lgb})\n",
    "sub.to_csv('lgb_model.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dcf6a-1e42-4c81-962b-699c0152a3bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# trying other things"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
